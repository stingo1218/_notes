平时2+上机2+考试6

 

# 1.大数据概述

## 1.1大数据时代

|        |            |          |
| ------ | ---------- | -------- |
| 第一次 | 个人计算机 | 信息处理 |
| 第二次 | 互联网     | 信息传输 |
| 第三次 | 大数据     | 信息爆炸 |

**信息科技提供技术支撑**

1. 存储设备容量不断增加
2. CPU处理能力大幅提升
3. 网络带宽不断增加

**数据产生方式的变革促成大数据时代**

运营式系统阶段--->用户原创内容阶段--->感知式系统阶段

**大数据发展历程**

| 阶段                   | 内容               |
| ---------------------- | ------------------ |
| 第一阶段：萌芽期       | 数据仓库，专家系统 |
| 第二季度：成熟期       | Web2.0             |
| 第三阶段：大规模应用期 | 大数据渗透各行业   |

## 1.2大数据概念

大数据是指大小超出典型数据库软件的采集，存储，管理和分析等能力的数据集。

**大数据特性**

- 大量化
- 快速化
- 多样化
- 价值密度低

### 1.2.1数据量大

每两年增加一倍

### 1.2.2数据种类繁多

- 10%结构化数据
- 90%非结构化数据

### 1.2.3处理速度快

生成到消耗时间非常小

### 1.2.4价值密度低

监控可用数据只有一两秒

但是商业价值高

## 1.3大数据的影响

1. 科学研究四种范式
   1. 实验
   2. 理论
   3. 计算
   4. 数据
2. 抽样--->全样
3. 精确--->效率
4. 寻求因果--->寻求相关
   - 几名演员--->出演的电视剧
   - 谷歌根据搜索词预测流感

## 1.4大数据关键技术

| 技术层面       | 功能   |
| -------------- | ------ |
| 数据采集       | 。。。 |
| 数据存储和管理 | 。。。 |
| 数据处理与分析 | 。。。 |
| 数据隐私和安全 | 。。。 |

**<u>两大核心技术</u>**

1. 分布式存储
2. 分布式处理

## 1.5大数据计算模式

| 大数据计算模式 | 解决问题                       | 代表产品 |
| -------------- | ------------------------------ | -------- |
| 批处理         | 大规模数据                     | Spark    |
| 流计算         | 流数据实时计算                 | Fink     |
| 图计算         | 大规模图结构数据               | Pregel   |
| 查询分析       | 大规模数据的存储管理和分析查询 | Dremel   |

## 1.6大数据产业

## 1.7大数据与云计算，物联网关系

云计算,大数据和物联网代表了IT领域的最新的技术发展趋势,三者相辅相成,既有联系又有区别

### 1.云计算

可伸缩廉价的分布式计算能力,需要接入网络

- 公有云
- 私有云
- 混合云

层

- IaaS   Infrastructure as a Service
  - 将基础设施计算资源和存储作为服务出租
- PaaS Platform as a Service
  - 类似IaaS,提供操作系统和特定应用
- SaaS   Software as a Service
  - 软件服务

### 2.云计算关键技术

- 虚拟化
- 分布式存储
- 分布式计算
- 多租户

### 3.云计算数据中心

- 复杂的设施,各种设备
- 云计算重要载体,提供硬件资源和支撑环境
- 全国各地推进数据中心建设

### 4.云计算应用

### 5.云计算产业

## 2.物联网

## 3.大数据 云计算 物联网关系

- 云计算为大数据提供积水处
- 大数据为云计算提供用武之地
- 物联网是大数据重要来源
- 大数据技术为物联网数据分析提供支撑
- 云计算为物联网提供数据存储
- 物联网为云计算提供广阔应用空间

# 2.大数据处理架构Hadoop

## 2.1 大数据技术难题

- 海量数据存储
  - 之前采用NFS-网络文件系统
- 海量数据处理
  - 硬件提升
  - 集群

## 2.2 Hadoop

- 开源分布式计算平台
- JAVA开发
- 核心:
  - 分布式文件系统HDFS   
  - MapReduce计算

- 特性
  - 高可靠性
  - 高效性
  - 高可拓展性
  - 高容错性
  - 成本低
  - Linux
  - 多种编程语言

## 2.3 Hadoop项目结构

![img](https://gitee.com/yonaspigeon/giteepicstore/raw/master/master/20220307115947.webp)

![IMG_9784(20220307-121208)](https://gitee.com/yonaspigeon/giteepicstore/raw/master/master/20220307121348.JPG)（1）`Sqoop`：Sqoop 是一款开源的工具，主要用于在Hadoop、Hive 与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到Hadoop 的HDFS 中，也可以将HDFS 的数据导进到关系型数据库中。
（2）`Flume`：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据。
（3）`Kafka`：Kafka 是一种高吞吐量的分布式发布订阅消息系统。
（4）`Spark`：Spark 是当前最流行的开源大数据内存计算框架。可以基于Hadoop 上存储的大数据进行计算。
（5）`Flink`：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。
（6）`Oozie`：Oozie 是一个管理Hadoop 作业（job）的工作流程调度管理系统。
（7）`Hbase`：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。
（8）`Hive`：Hive 是基于Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL 查询功能，可以将SQL 语句转换为MapReduce 任务进行运行。其优点是学习成本低，可以通过类SQL 语句快速实现简单的MapReduce 统计，不必开发专门的MapReduce 应用，十分适合数据仓库的统计分析。
（9)`ZooKeeper`：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等。

# 3.分布式文件系统HDFS(Hadoop Distributed File System)

## 3.1分布式文件系统

### 3.1.1计算机集群结构

- 分布式文件把文件分布存储到多个计算机节点上
- 采用计算机集群,普通<u>**廉价**</u>硬件构成

### 3.1.2分布式文件系统的结构

**主从架构**

计算机集群节点分为两类

- 主节点/名称节点
- 从节点/数据节点---存储数据

访问顺序:主--->从

## 3.2HDFS简介

**实现目标**:

1. 兼容廉价的硬件设备
2. 流数据读写
3. 大数据集
4. 简单的文件模型
   - 只能一次写入但可多次读取
5. 强大的跨平台兼容性

**局限性:**

- 不适合<u>低延迟</u>数据访问
- 无法高效存储<u>大量小文件</u>
- 不支持<u>多用户写入</u>以及<u>任意修改文件</u>



## 3.3HDFS相关概念

### 3.3.1块

HDFS默认一个块 **64MB**,一个文件分为多个块,以**块作为存储单位**

块的大小远大于普通文件系统

**优点**:

- 支持大规模文件存储
  - 可拆分放入节点
- 简化系统设计
  - 容易计算一个节点存储多少块
  - 方便元数据存储,不需要和文件块一起存储
- 适合数据备份
  - 可以冗余存储



### 3.3.2名称节点和数据节点

#### 名称节点

- 存储元数据
- 元数据保存在内存
- 保存文件,block到databode之间映射关系

#### **数据节点**

- 存储文件内容
- 文件内容存在磁盘
- 维护block id 到datanode本地文件的映射关系
- HDFS的工作节点
- 每个数据节点保存在本地Linux系统上

#### 名称节点的数据结构

两个核心数据结构`Fslmage` 和`EditLog`

**Fslmage**:

- 维护文件系统树以及树中所有文件和文件界的元数据操作
- Fslmage文件包含所有目录和文件inode的序列化形式
- **Fslmage文件没有记录每个块存储的数据节点**
- 由名称节点把映射信息保留在内存中

**EditLog**:

- 记录了所有对文件的操作

#### 名称节点的启动

- 启动时会将Fslmage文件内容加载到内存,再执行EditLog文件里的各项操作,是内存中的元数据和实际同步
- 一旦在内存中成功创建文件系统元数据的映射,则创建一个新的Fslmage文件和一个空的EditLog文件
- 名称节点启动后,HDFS的更新操作会重新写道EditLog文件中,因为Fslmage文件很大

#### 名称节点运行期间EditLog扩大问题

- 当EditLog非常大时,会导致名称节点启动非常慢

#### 第二名称节点

- 解决EditLog不断扩大问题
- 解决冷备份
- 单独运行在一台机器上



## 3.4HDFS体系结构

### 3.4.1.HDFS体系结构概述---考点

主从结构

一个HDFS集群包括**一个名称节点**和**若干数据节点**

名称节点作为中心服务器,数据节点负责处理文件系统客户端读写请求

### 3.4.2

- HDFS命名空间过包括  **目录 文件  块**
- 在1.0中只有一个命名空间,只有一个名称节点
- 使用传统的分级文件体系

### 3.4.3通信协议---考点

- 部署在集群上,所以要天网络进行传输
- 所有通信协议构建在**TCP/IP**协议上
- 客户端使用可配置的端口像名称节点主动发起TCP连接
- 名称节点和数据节点使用数据节点进行交互
- 客户端和数据节点的交互通过RPC实现

### 3.4.4客户端

- 客户端是操作HDFS常用方式
- HDFS客户端是一个库,暴露了HDFS文件系统的接口
- 严格来说客户端并不是HDFS一部分
- 客户端可以打开读取等,提供了命令行访问数据
- 提供Java API作为应用程序访问文件系统的客户端编程接口

### 3.4.5局限性

**只有一个名称节点带来的问题**

- 命名空间限制
  - 名称节点存内存,容纳对象有限制
- 性能瓶颈
  - 整个系统吞吐量受限于单个名称节点吞吐量
- 隔离问题
  - 只有一个名称节点,无法对不同应用程序进行隔离
- 集群可用性
  - 唯一节点发生故障会导致整个集群不可用

## 3.5HDFS存储原理

### 3.5.1冗余数据保存

采用多副本方式保存冗余数据(数据A被分别放到A节点A和C上)

**优点**

- 加快数据传输速度
- 容易检查数据错误
- 保证数据可靠性



### 3.5.2数据存取策略

#### 1.数据存放策略

- 第一个副本:放在**上传文件的数据节点**;集群外提交,则随机挑选磁盘不太满的,cpu不太忙的节点
- 第二个副本:放置在与第一个副本**不同的机架的节点**
- 第三个副本:与第一个副本**相同机架的其他节点上**
- 更多副本:**随机节点**

#### 2.数据读取策略

**就近原则**

调用API确定客户端和数据节点所属的机架ID,发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时,就优先选择该副本读取数据



### 3.5.3数据错误与恢复

#### 1.名称节点出错

Fslmage和EditLog损坏时,整个HDFS实例将会失效.

HDFS备份机制会把核心文件备份到服务器SecondaryNameNode,出错时会根据服务器里的文件进行恢复

#### 2.数据结点出错

定时向名称节点发送"心跳"信息,无法收到时数据节点标记为"宕机",节点上的所有数据会被标记为"不可读'',名称节点不会再向他们发送任何I/O请求.

当数据节点的不可用导致一些数据块的副本熟料小于冗余因子,名称节点会定期检查启动数据冗余复制,生成新的副本.

#### 3.数据出错

- 网络原因/.磁盘错误等原因
- 客户端读取到数据后使用md5和sha1进行校验确定读取正确信息
- 文件被创建时客户端会对每一个文件块进行信息摘录,把这些信息写入同一个路径的隐藏文件里
- 客户端读取文件会优先读取信息文件,利用信息文件校验,如果出错会向名称节点报告文件块有错误,名称节点会定期检查重新复制

## 3.6HDFS数据读写过程

- **FileSystem是一个通用文件系统的抽象基类**,基本上所有使用Hadoop文件系统的代码都要用到这个类
- **FileSystem的open()**返回输入流对象**FSDatalnputStream** 
  - 在HDFS中输入流为**DFSInputStream**
- **FileSystem的create()**返回**FSDataOutoutStream**对象
  - 在HDFS中为**DFSOputputStream**

### **3.6.1读数据的过程**

<img src="C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220321111333565.png" alt="image-20220321111333565" style="zoom:50%;" />

### **3.6.2写数据的过程**

<img src="https://gitee.com/yonaspigeon/giteepicstore/raw/master/master/20220321111222.png" alt="image-20220321111222139" style="zoom:50%;" />

1. client向NameNode发送写文件请求；
2. NameNode检查文件，如果通过就返回输出流对象；
3. client切分文件并且把数据和NameNode返回的DataNode列表一起发送给最近的一个DataNode节点；
4. DataNode写完之后返回确认信息；
5. 数据全部写完，关闭输入输出流，并发送完成信号给NameNode。

# 4.分布式数据库HBase

## 4.1概述

### 4.1.1BigTable

一个分布式存储系统

解决典型的互联网搜索问题

- 建立互联网索引
  1. 爬虫不断抓取,每夜一行存储到BigTable
  2. MapReduce计算作业运行在整张表生成索引
- 搜索互联网
  3. 用户发起网络请求
  4. 网络搜索应用查询建立好的索引
  5. 搜索结果提交给用户

### 4.1.2HBase

BigTable开源实现,高可靠,高性能,面向列,可伸缩的数据库

#### 为什么需要Hbase?

- Hadoop可以解决大规模离线批量处理问题,但是受限于高延迟数据处理机制
- HDFS面向批量访问模式

### 4.1.3Hbase和传统关系数据库对比

1. **数据类型** 
   - 关系数据库:关系模型
   - Hbase:更简单的数据模型,未经解释的字符串
2. **数据操作**
   - 关系数据库:丰富操作(多表连接)
   - Hbase:插入查询删除等简单操作
3. **存储模式**
   - 关系数据库:行模式
   - Hbase:列存储,每个列族有几个文件保存,不同列族文件是分离的
4. **数据索引**
   - 关系数据库:多个索引
   - HB:一个索引——行键
5. **数据维护**
   - 关系数据库:更新操作用最新当前值替换旧值
   - HB:不会删除旧版本,而是生成新版本
6. **可伸缩性**
   - 关系数据库:难以横向拓展
   - HB:灵活水平拓展,轻易通过增加减少硬件实现性能伸缩

## 4.2访问接口

![img](https://gitee.com/yonaspigeon/giteepicstore/raw/master/master/20220321120452.png)

## 4.3数据模型

- HB是一个稀疏的,多维度,排序的映射表,索引是行键,列族,列限定符和时间戳
- 每个值是一个未经解释的字符串,没有数据类型
- 表中每一行都有一个可排序的行键和任意多的列
- 表在水平方向由一个或者多个列族组成,一个列族可以包含多个列,同一列族数据存储在一起
- 列族支持动态拓展,所有列都以字符串形式存储,用户需要自自行进行数据类型转换
- Hbase更新不删除旧数据,直接生成新数据

### 4.3.2数据模型相关概念

- 表
  - HBase采用表来组织数据
- 行
  - 每个HBase表由若干行组成
- 列族
  - 一个HBase表被分组成许多列族的集合
- 列限定符
  - 列族里的数据通过列限定符来定位
- 单元格
  - 在HBase表中通过行列族和列限定符确定一个单元格
- 时间戳
  - 每个单元格保存着同一份数据的多个版本

![img](https://upload-images.jianshu.io/upload_images/6584864-fb6ad989c0fcf8c2.png?imageMogr2/auto-orient/strip|imageView2/2/w/1072/format/webp)

### 4.3.6 面向列的存储

- 高压缩率
- 节省空间

## 4.4HBase实现原理

### 4.4.1HBase功能组件

- **空函数**
- **一个master主服务器**
  - 负责**管理和维护**HBase表的分区信息,维护Region服务器列表,分配Region,负载均衡
- **许多region服务器**
  - 负责存储和维护分配给自己的Region,处理来自客户端的读写请求
  - 客户端并不是直接从Master主服务器上读取水,二货思在获得Region的存储位置后直接从Region服务器上读取数据
  - 客户端并不依赖Master,而是通过**Zookeeper**来获得Region位置信息,大多客户端甚至从来不和Master通信,这种设计方法使Master负载很小

### 4.4.2表和Region

- 开始只有一个Region,后来不断分裂
- Region拆分操作非常快,接近瞬间,因为拆分之后的Region读取的忍让是原存储文件,知道合并过程把存储文件异步写到独立的文件之后,才会读取新文件

- 每个Region默认大小是100MB到200MB
  - 每Region最佳大小取决于单台服务器的有效处理能力
  - 目前每个Region最佳大小建议1GB~2GB
- 同一个Region不会被拆分到多个Region服务器
- 每个Region服务器存储10-1000个Region

![image-20220328111630462](C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328111630462.png)

### 4.4.3Region的定位

- 元数据表,又名.META表,存储了Region和Region服务器的映射关系
- 当HBase表很大时,.META表也会被分裂为多个Region
- 根数据表,又名-ROOT-表,记录所有元数据的具体位置
- -ROOT-表只有唯一一个Region,名字是在程序中被写死的
- Zookeeper文件记录了-ROOT-表的位置

![image-20220328111701904](C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328111701904.png)

![image-20220328113330279](C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328113330279.png)

![image-20220328113424117](C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328113424117.png)

<img src="C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328113435492.png" alt="image-20220328113435492" style="zoom: 80%;" />

- 为了加速寻址,客户端会缓存位置信息,同时需要解决缓存失效的问题
- 寻址过程客户端只需要询问Zookeeper服务器,不需要连接Master服务器

## 4.5HBase运行机制

### 4.5.1HBase系统架构

![image-20220328114339710](C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328114339710.png)

#### 1.客户端

包含访问HBase的接口,同时在缓存中维护

#### 2.Zoopkeeper

#### 3.Master

主服务器Master主要负责和Region的管理工作

- 管理永和对表的增加,删除,修改,查询等
- 实现不同Region服务器之间的负载均衡

#### 4.Region服务器

- HBase核心模块

### 4.5.2Region服务器工作原理

1. 用户读写数据过程
   - 用户写入数据时,被分配到相应Region服务器去执行
   - 用户数据首先被写入到MemStore和HLog中
   - 只有当操作写入Hlog后,commit()调用才会将其返回给客户端
2. 缓存的刷新
   - 系统会周期性把MEMStoree缓存里的内容刷写到磁盘StoreFile文件,清空缓存并在Hlog写入一个标记
   - 每次刷写都生成一个StorFile文件,因此每个Store包含多个StoreFile文件
   - 每个Region服务器都有一个自己的Hlog文件,每次启动都检查该文件,确认最近一次执行缓存刷新操作之后是否发生新的写入操作,如果发型更新,则先写入MemStore在刷写到StoreFile,最后删除旧的Hlog文件,开始为用户提供服务
3. StoreFile的合并
   - 每次刷写生成一个新的StoreFile,数量太多,影响查找速度
   - 应用Stor.Compact()把多个合并为一个
   - 合并操作作比较耗费电源,只有数量达到一个阈值才启动合并

![image-20220328114842203](C:\Users\syc\AppData\Roaming\Typora\typora-user-images\image-20220328114842203.png)

### 4.5.3Store工作原理

- Store是Region服务器的核心
- 多个StoreFile合并成一个
- 单个StoreFile过大时,触发分裂操作,一个父Region被分裂为两个子Region

### 4.5.4HLog工作原理

- 分布式环境必须考虑系统出错,HBase采用HLog保证系统恢复
- HBase为每一个Region服务器配置了一个HLog文件,它是一种预写式日志
- 用户更新数据必须首先写入日志

#### 恢复原理

公用日志优点缺点:

- 提高对标的写操作性能
- 恢复时需要拆分日志

## 4.6HBase应用方案

### 4.6.1HBase实际应用中的性能优化方法

#### 行键

行键按照字典序存储,因此设计行键要充分利用特点将经常一起读取的数据存储到一起,将最近可能会被访问的放在一起

#### InMemory

创建表时,将表放到Region服务器方缓存

#### Max Version

创建表时设置最大版本

#### Time To Live

创建表时设置表中数据的存储生命期,过期自动删除

# 第5章 NoSQL数据库

## 5.1  NoSQL简介

![image-20220404105014085](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404105014.png)

通常，NoSQL数据库具有以下几个特点：

- 灵活的可扩展性
- 灵活的数据模型
- 与云计算紧密融合

现在已经有很多公司使用了NoSQL数据库：

•Google

•Facebook

•Mozilla

•Adobe

•Foursquare

•LinkedIn

•Digg

•McGraw-Hill Education

•Vermont Public Radio

•百度、腾讯、阿里、新浪、华为……

## 5.2 NoSQL兴起的原因

### 1.关系数据库已经无法满足Web2.0的需求

1. 无法满足**海量数据的管理**需求
2. 无法满足**数据高并发**的需求
3. 无法满足**高可扩展性和高可用性**的需求

#### MySQL集群面对的问题

•**复杂性**：部署、管理、配置很复杂

•**数据库复制**：MySQL主备之间采用复制方式，只能是异步复制，当主库压力较大时可能产生较大延迟，主备切换可能会丢失最后一部分更新事务，这时往往需要人工介入，备份和恢复不方便

•**扩容问题**：如果系统压力过大需要增加新的机器，这个过程涉及数据重新划分，整个过程比较复杂，且容易出错

•**动态数据迁移问题**：如果某个数据库组压力过大，需要将其中部分数据迁移出去，迁移过程需要总控节点整体协调，以及数据库节点的配合。这个过程很难做到自动化

![image-20220404110000645](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404110000.png)

### 2.“One size fits all”模式很难适用于截然不同的业务场景

关系模型作为统一的数据模型既被用于数据分析，也被用于在线业务。但这两者一个强调高吞吐，一个强调低延时，已经演化出完全不同的架构。用同一套模型来抽象显然是不合适的

- Hadoop就是针对数据分析
- MongoDB、Redis等是针对在线业务，两者都抛弃了关系模型

### 3.关系数据库的关键特性

包括**完善的事务机制和高效的查询机制**。但是，关系数据库引以为傲的两个关键特性，到了Web2.0时代却成了鸡肋，主要表现在以下几个方面：

1. Web2.0网站系统通常**不要求严格的数据库事务**
2. Web2.0并**不要求严格的读写实时性**
3. Web2.0通常**不包含大量复杂的SQL查询**（去结构化，存储空间换取更好的查询性能）

#### NoSQL和关系数据库的简单比较 

![image-20220404111740461](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404111740.png)

![image-20220404111822309](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404111822.png)

![image-20220404112544881](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404112545.png)



## 5.3  NoSQL与关系数据库的比较

### 总结

- 关系数据库
  - **优势**：以完善的关系代数理论作为基础，有严格的标准，支持事务ACID四性，借助索引机制可以实现高效的查询，技术成熟，有专业公司的技术支持
  - **劣势**：可扩展性较差，无法较好支持海量数据存储，数据模型过于死板、无法较好支持Web2.0应用，事务机制影响了系统的整体性能等

- NoSQL数据库
  - **优势**：可以支持超大规模数据存储，灵活的数据模型可以很好地支持Web2.0应用，具有强大的横向扩展能力等
  - **劣势**：缺乏数学理论基础，复杂查询性能不高，大都不能实现事务强一致性，很难实现数据完整性，技术尚不成熟，缺乏专业团队的技术支持，维护较困难等

**关系数据库和NoSQL数据库各有优缺点，彼此无法取代**

- **关系数据库**应用场景：**电信、银行等领域的关键业务系统**，需要保证强事务**一致性**
- **NoSQL数据库**应用场景：**互联网企业、传统企业的非关键业务**（比如数据分析）

**<u>采用混合架构</u>**

> 案例：亚马逊公司就使用**不同类型的数据库**来支撑它的电子商务应用,对于“购物篮”这种临时性数据，采用键值存储会更加高效,当前的产品和订单信息则适合存放在关系数据库中,大量的历史订单信息则适合保存在类似MongoDB的文档数据库中

## 5.4 NoSQL的四大类型(**考点**)

​        NoSQL数据库虽然数量众多，但是，归结起来，典型的NoSQL数据库通常包括**键值数据库、列族数据库、文档数据库和图形数据库**

![image-20220404113935960](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404113936.png)

![image-20220404113942861](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404113942.png)

![image-20220404114250555](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404114250.png)

### 5.4.1  键值数据库

![图片1](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404114452.png)

#### 键值数据库成为理想的**缓冲层**解决方案

![image-20220404114904990](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404114905.png)

Redis有时候会被人们称为“强化版的Memcached” , 支持持久化、数据恢复、更多数据类型

### 5.4.2  列族数据库

![图片2](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404115033.png)

### 5.4.3  文档数据库

“文档”其实是一个数据记录，这个记录能够对包含的数据类型和内容进行“自我描述”。XML文档、HTML文档和JSON 文档就属于这一类。SequoiaDB就是使用JSON格式的文档数据库，它的存储的数据是这样的：

![image-20220404115426647](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404115426.png)

![image-20220404115539283](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404115539.png)

- 数据是不规则的，每一条记录包含了所有的有关“SequoiaDB”的信息而没有任何外部的引用，这条记录就是“自包含”的
- 这使得记录很容易完全移动到其他服务器，因为这条记录的所有信息都包含在里面了，不需要考虑还有信息在别的表没有一起迁移走
- 同时，因为在移动过程中，只有被移动的那一条记录（文档）需要操作，而不像关系型中每个有关联的表都需要锁住来保证一致性，这样一来ACID的保证就会变得更快速，读写的速度也会有很大的提升

![图片3](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404115746.png)

### 5.4.4  图形数据库

![图片4](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404115957.png)

### 5.4.5 不同类型数据库比较分析

•**MySQL**产生年代较早，而且随着LAMP大潮得以成熟。尽管其没有什么大的改进，但是新兴的互联网使用的最多的数据库

•**MongoDB**是个新生事物，提供更灵活的数据模型、异步提交、地理位置索引等五花十色的功能

•**HBase**是个“仗势欺人”的大象兵。依仗着Hadoop的生态环境，可以有很好的扩展性。但是就像象兵一样，使用者需要养一头大象(Hadoop),才能驱使他

•**Redis**是键值存储的代表，功能最简单。提供随机数据存储。就像一根棒子一样，没有多余的构造。但是也正是因此，它的伸缩性特别好。就像悟空手里的金箍棒，大可捅破天，小能成缩成针

## 5.5  NoSQL的三大基石

### 5.5.1  CAP

所谓的CAP指的是：

- **C（Consistency）**：**一致性**，是指任何一个读操作总是能够读到之前完成的写操作的结果，也就是在分布式环境中，多点的数据是一致的，或者说，所有节点在同一时间具有相同的数据
- **A:（Availability）**：**可用性**，是指快速获取数据，可以在确定的时间内返回操作结果，保证每个请求不管成功或者失败都有响应；
- **P（Tolerance of Network Partition**）：**分区容忍性**，是指当出现网络分区的情况时（即系统中的一部分节点无法和其他节点进行通信），分离的系统也能够正常运行，也就是说，系统中任意信息的丢失或失败不会影响系统的继续运作。

CAP理论告诉我们，一个分布式系统不可能同时满足一致性、可用性和分区容忍性这三个需求，**最多只能同时满足其中两个**，正所谓“鱼和熊掌不可兼得”。

![image-20220404120948143](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404120948.png)

> **一个牺牲一致性来换取可用性的实例** 
>
> ![image-20220404121025327](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404121025.png)
>
> ![image-20220404121123020](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404121123.png)
>
> ![image-20220404121231765](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220404121231.png)

当处理CAP的问题时，可以有几个明显的选择：

1.**CA**：也就是强调一致性（C）和可用性（A），放弃分区容忍性（P），最简单的做法是把所有与事务相关的内容都放到同一台机器上。很显然，这种做法会严重影响系统的可扩展性。传统的关系数据库（MySQL、SQL Server和PostgreSQL），都采用了这种设计原则，因此，扩展性都比较差

2.**CP**：也就是强调一致性（C）和分区容忍性（P），放弃可用性（A），当出现网络分区的情况时，受影响的服务需要等待数据一致，因此在等待期间就无法对外提供服务

3.**AP**：也就是强调可用性（A）和分区容忍性（P），放弃一致性（C），允许系统返回不一致的数据

![image-20220411104615138](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411104615.png)

### 5.5.2  BASE

一个数据库事务具有ACID四性：

- **A（Atomicity）：原子性**，是指事务必须是原子工作单元，对于其数据修改，要么全都执行，要么全都不执行
- **C（Consistency）：一致性**，是指事务在完成时，必须使所有的数据都保持一致状态
- **I（Isolation）：隔离性**，是指由并发事务所做的修改必须与任何其它并发事务所做的修改隔离
- **D（Durability）：持久性**，是指事务完成之后，它对于系统的影响是永久性的，该修改即使出现致命的系统故障也将一直保持

**BASE**的基本含义是**基本可用（Basically Availble）、软状态（Soft-state）和最终一致性（Eventual consistency）**：

- **基本可用**

基本可用，是指一个分布式系统的一部分发生问题变得不可用时，其他部分仍然可以正常使用，也就是允许分区失败的情形出现

- **软状态**

“软状态（soft-state）”是与“硬状态（hard-state）”相对应的一种提法。数据库保存的数据是“硬状态”时，可以保证数据一致性，即保证数据一直是正确的。“软状态”是指状态可以有一段时间不同步，具有一定的滞后性

- **最终一致性**

一致性的类型包括强一致性和弱一致性，二者的主要区别在于高并发的数据访问操作下，后续操作是否能够获取最新的数据。对于强一致性而言，当执行完一次更新操作后，后续的其他读操作就可以保证读到更新后的最新数据；反之，如果不能保证后续访问读到的都是更新后的最新数据，那么就是弱一致性。而最终一致性只不过是弱一致性的一种特例，允许后续的访问操作可以暂时读不到更新后的数据，但是经过一段时间之后，必须最终读到更新后的数据。

最常见的实现最终一致性的系统是DNS（域名系统）。一个域名更新操作根据配置的形式被分发出去，并结合有过期机制的缓存；最终所有的客户端可以看到最新的值。

- **最终一致性**根据更新数据后各进程访问到数据的时间和方式的不同，又可以区分为：
    - **因果一致性**：如果进程A通知进程B它已更新了一个数据项，那么进程B的后续访问将获得A写入的最新值。而与进程A无因果关系的进程C的访问，仍然遵守一般的最终一致性规则
    - **“读己之所写”一致性**：可以视为因果一致性的一个特例。当进程A自己执行一个更新操作之后，它自己总是可以访问到更新过的值，绝不会看到旧值
    - **单调读一致性**：如果进程已经看到过数据对象的某个值，那么任何后续访问都不会返回在那个值之前的值

    - **会话一致性**：它把访问存储系统的进程放到会话（session）的上下文中，只要会话还存在，系统就保证“读己之所写”一致性。如果由于某些失败情形令会话终止，就要建立新的会话，而且系统保证不会延续到新的会话
    - **单调写一致性**：系统保证来自同一个进程的写操作顺序执行。系统必保证这种程度的一致性，否则就非常难以编程了

  

#### 如何实现各种类型的一致性？

对于分布式数据系统：

- N — 数据复制的份数(总结点个数)
- W — 更新数据是需要保证写完成的节点数
- R — 读取数据的时候需要读取的节点数

如果W+R>N，写的节点和读的节点重叠，则是强一致性。例如对于典型的一主一备同步复制的关系型数据库，N=2,W=2,R=1，则不管读的是主库还是备库的数据，都是一致的。一般设定是R＋W = N+1，这是保证强一致性的最小设定

如果W+R<=N，则是弱一致性。例如对于一主一备异步复制的关系型数据库，N=2,W=1,R=1，则如果读的是备库，就可能无法读取主库已经更新过的数据，所以是弱一致性。

### 5.5.3 最终一致性

对于分布式系统，为了保证高可用性，一般设置N>=3。不同的N,W,R组合，是在可用性和一致性之间取一个平衡，以适应不同的应用场景。



- 如果N=W,R=1，任何一个写节点失效，都会导致写失败，因此可用性会降低，但是由于数据分布的N个节点是同步写入的，因此可以保证强一致性。



实例：HBase是借助其底层的HDFS来实现其数据冗余备份的。HDFS采用的就是强一致性保证。在数据没有完全同步到N个节点前，写操作是不会返回成功的。也就是说它的W＝N，而读操作只需要读到一个值即可，也就是说它R＝1。



- 像Voldemort，Cassandra和Riak这些类Dynamo的系统，通常都允许用户按需要设置N，R，W三个值，即使是设置成W＋R<= N也是可以的。也就是说他允许用户在强一致性和最终一致性之间自由选择。而在用户选择了最终一致性，或者是W<N的强一致性时，则总会出现一段“各个节点数据不同步导致系统处理不一致的时间”。为了提供最终一致性的支持，这些系统会提供一些工具来使数据更新被最终同步到所有相关节点。

## 5.6  从NoSQL到NewSQL数据库

![image-20220411110809140](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411110809.png)

**考点**

NoSQL类型

![image-20220411111042419](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411111042.png)

# 第6章 云数据库

### 6.1.1	云计算是云数据库兴起的基础

**云计算特点**

通过整合、管理、调配分布在网络各处的计算资源，通过互联网以统一界面，同时向大量的用户提供服务

### 6.1.2	云数据库概念

云数据库是部署和虚拟化在云计算环境中的数据库。云数据库是在云计算的大背景下发展起来的一种新兴的**共享基础架构**的方法，它极大地增强了数据库的存储能力，消除了人员、硬件、软件的重复配置，让软、硬件升级变得更加容易。云数据库具有**高可扩展性、高可用性、采用多租形式和支持资源有效分发**等特点。

![image-20220411111422964](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411111423.png)

**云数据库具有以下特性**： 

（1）动态可扩展

（2）高可用性 

（3）较低的使用代价 

（4）易用性 

（5）高性能 

（6）免维护 

（7）安全  

![image-20220411111601267](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411111601.png)

### 6.1.4	云数据库是个性化数据存储需求的理想选择

企业类型不同，对于存储的需求也千差万别，而云数据库可以很好地满足不同企业的个性化存储需求：

首先，云数据库可以满足**大企业的海量数据存储需求**

其次，云数据库可以满足**中小企业的低成本数据存储需求** 

另外，云数据库可以满足**企业动态变化的数据存储需求**  

到底选择自建数据库还是选择云数据库，取决于企业自身的具体需求 

对于一些**大型企业**，目前通常采用**自建数据库** (安全性考虑)

对于一些财力有限的**中小企业**而言，IT预算比较有限，**云数据库这种前期零投入、后期免维护**的数据库服务，可以很好满足它们的需求  

### 6.1.5 云数据库与其他数据库的关系

- 从数据模型的角度来说，云数据库并非一种全新的数据库技术，而只是**以服务的方式提供数据库功能**

- **云数据库并没有专属于自己的数据模型**，云数据库所采用的数据模型可以是关系数据库所使用的关系模型（微软的SQL Azure云数据库、阿里云RDS都采用了关系模型），也可以是NoSQL数据库所使用的非关系模型（Amazon Dynamo云数据库采用的是“键/值”存储）

- 同一个公司也可能提供采用不同数据模型的多种云数据库服务

- 许多公司在开发云数据库时，后端数据库都是直接使用现有的各种关系数据库或NoSQL数据库产品

![image-20220411112116185](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411112116.png)

## 6.2	云数据库产品

### 6.2.1	云数据库厂商概述

| 企业        | 产品                                  |
| ----------- | ------------------------------------- |
| Amazon      | Dynamo、SimpleDB、RDS                 |
| Google      | Google  Cloud SQL                     |
| Microsoft   | Microsoft  SQL Azure                  |
| Oracle      | Oracle  Cloud                         |
| Yahoo!      | PNUTS                                 |
| Vertica     | Analytic  Database v3.0 for the Cloud |
| EnerpriseDB | Postgres  Plus in the Cloud           |
| 阿里        | 阿里云RDS                             |
| 百度        | 百度云数据库                          |
| 腾讯        | 腾讯云数据库                          |

### 6.2.2 Amazon的云数据库产品

Amazon是云数据库市场的先行者。Amazon除了提供著名的S3存储服务和EC2计算服务以外，还提供基于云的数据库服务：

- Amazon RDS：云中的关系数据库
- Amazon SimpleDB：云中的键值数据库
- Amazon DynamoDB：云中的NoSQL数据库
- Amazon Redshift：云中的数据仓库
- Amazon ElastiCache：云中的分布式内存缓存

### 6.2.3	Google的云数据库产品

Google Cloud SQL是谷歌公司推出的**基于MySQL的云数据库**

- 使用Cloud SQL，所有的事务都在云中，并由谷歌管理，用户不需要配置或者排查错误
- 谷歌还提供**导入或导出服务**，方便用户将数据库带进或带出云
- 谷歌使用用户非常熟悉的MySQL，带有**JDBC支持**（适用于基于Java的App Engine应用）和**DB-API支持**（适用于基于Python的App Engine应用）的传统MySQL数据库环境，因此，多数应用程序不需过多调试即可运行，数据格式对于大多数开发者和管理员来说也是非常熟悉的
- Google Cloud SQL还有一个好处就是与**Google App Engine集成**

### 6.2.4	Microsoft的云数据库产品

SQL Azure具有以下特性：

•**属于关系型数据库**：支持使用TSQL（Transact Structured Query Language）来管理、创建和操作云数据库

•**支持存储过程**：它的数据类型、存储过程和传统的SQL Server具有很大的相似性，因此，应用可以在本地进行开发，然后部署到云平台上

•**支持大量数据类型**：包含了几乎所有典型的SQL Server 2008的数据类型

•**支持云中的事务**：支持局部事务，但是不支持分布式事务 

## 6.3 云数据库系统架构

### 6.3.1	UMP系统概述

UMP系统是低成本和高性能的MySQL云数据库方案

总的来说，**UMP系统架构设计遵循了以下原则：**

- 保持单一的系统对外入口，并且为系统内部维护单一的资源池
- 消除单点故障，保证服务的高可用性
- 保证系统具有良好的可伸缩，能够动态地增加、删减计算与存储节点
- 保证分配给用户的资源也是弹性可伸缩的，资源之间相互隔离，确保应用和数据安全

### 6.3.2 UMP系统架构

**UMP系统中的角色包括：**

- Controller服务器
- Proxy服务器
- Agent服务器
- Web控制台
- 日志分析服务器
- 信息统计服务器
- 愚公系统

**依赖的开源组件包括：**

- Mnesia
- LVS
- RabbitMQ
- ZooKeeper 

![image-20220411113932796](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411113933.png)

#### 1. Mnesia 

- Mnesia是一个**分布式数据库管理系统**
- Mnesia**支持事务**，支持**透明的数据分片**，利用**两阶段锁**实现分布式事务，可以**线性扩展**到至少50个节点 
- Mnesia的数据库模式(schema)可在运行时**动态重配置**，表**能被迁移或复制**到多个节点来改进容错性
- Mnesia的这些特性，使其在开发云数据库时被用来提供分布式数据库服务 

#### 2. RabbitMQ

- RabbitMQ是一个**工业级的消息队列产品**（功能类似于IBM公司的消息队列产品IBM Websphere MQ），作为消息传输中间件来使用，可以实现**可靠的消息传送**
- UMP集群中各个节点之间的通信，不需要建立专门的连接，都是通过读写队列消息来实现的

#### 3. Zookeeper

Zookeeper是**高效和可靠的协同工作系统**，提供分布式锁之类的基本服务（比如统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等），用于构建分布式应用，减轻分布式应用程序所承担的协调任务

在UMP系统中，**Zookeeper主要发挥三个作用(考点)：**

- **作为全局的配置服务器** 
- **提供分布式锁（选出一个集群的“总管”）** 
- **监控所有MySQL实例** 

#### 4.LVS

LVS(Linux Virtual Server)即**Linux虚拟服务器**，是一个虚拟的服务器集群系统

UMP系统借助于LVS来**实现集群内部的负载均衡**

LVS集群采用IP负载均衡技术和基于内容请求分发技术

调度器是LVS集群系统的唯一入口点，调度器具有很好的吞吐率，将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器

整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序

#### 5. Controller服务器 

- Controller服务器向UMP集群**提供各种管理服务**，实现集群成员管理、元数据存储、MySQL实例管理、故障恢复、备份、迁移、扩容等功能
- Controller服务器上运行了一组Mnesia分布式数据库服务，其中存储了各种系统元数据，主要包括集群成员、用户的配置和状态信息，以及用户名到后端MySQL实例地址的映射关系（或称为“路由表”）等
- 当其它服务器组件需要获取用户数据时，可以向Controller服务器发送请求获取数据
- 为了避免单点故障，保证系统的高可用性，UMP系统中部署了多台Controller服务器，然后，由Zookeeper的分布式锁功能来帮助选出一个“总管”，负责各种系统任务的调度和监控

6. #### Web控制台

  Web控制台向用户提供系统管理界面

7. #### Proxy服务器
  
    Proxy服务器**向用户提供访问MySQL数据库的服务**，它完全实现了MySQL协议，用户可以使用已有的MySQL客户端连接到Proxy服务器，Proxy服务器通过用户名获取到用户的认证信息、资源配额的限制(例如QPS、IOPS（I/O Per Second）、最大连接数等)，以及后台MySQL实例的地址，然后，用户的SQL查询请求会被转发到相应的MySQL实例上。
    
    除了**数据路由**的基本功能外，Proxy服务器中还实现了很多重要的功能，主要包括**屏蔽MySQL实例故障、读写分离、分库分表、资源隔离、记录用户访问日志等**

#### 8. Agent服务器

  Agent服务器部署在运行MySQL进程的机器上，用来**管理每台物理机上的MySQL实例**，执行主从切换、创建、删除、备份、迁移等操作，同时，还负责收集和分析MySQL进程的统计信息、慢查询日志（Slow Query Log）和bin-log

9. #### 日志分析服务器

日志分析服务器存储和分析Proxy服务器传入的用户访问日志，并支持实时查询一段时间内的慢日志和统计报表

10. #### 信息统计服务器

信息统计服务器定期将采集到的用户的连接数、QPS数值以及MySQL实例的进程状态用RRDtool进行统计，可以在 Web界面上可视化展示统计结果，也可以把统计结果作为今后实现弹性的资源分配和自动化的MySQL实例迁移的依据

11. #### 愚公系统

愚公系统是一个全量复制结合bin-log分析进行增量复制的工具，可以实现在不停机的情况下动态扩容、缩容和迁移

### 6.3.3 UMP系统功能

UMP系统是构建在一个大的集群之上的，通过多个组件的协同作业，整个系统实现了对用户透明的各种功能：

1. **容灾**	
   - ![image-20220411120546416](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411120546.png	)
   - ​	![image-20220411120619948](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411120620.png)

2. **读写分离**
   - 充分利用主从库实现用户读写操作的分离，实现负载均衡
   - UMP系统实现了对于用户透明的读写分离功能，当整个功能被开启时，负责向用户提供访问MySQL数据库服务的Proxy服务器，就会对用户发起的SQL语句进行解析，如果属于写操作，就直接发送到主库，如果是读操作，就会被均衡地发送到主库和从库上执行
3. **分库分表**
   - UMP支持对用户透明的分库分表（shard / horizontal partition） 
   - 当采用分库分表时，系统处理用户查询的过程如下：
   - 首先，Proxy服务器解析用户SQL语句，提取出重写和分发SQL语句所需要的信息
   - 其次，对SQL语句进行重写，得到多个针对相应MySQL实例的子语句，然后把子语句分发到对应的MySQL实例上执行
   - 最后，接收来自各个MySQL实例的SQL语句执行结果，合并得到最终结果 
4. **资源管理**
   - UMP系统采用资源池机制来管理数据库服务器上的CPU、内存、磁盘等计算资源，所有的计算资源都放在资源池内进行统一分配，资源池是为MySQL实例分配资源的基本单位
   - 整个集群中的所有服务器会根据其机型、所在机房等因素被划分多个资源池，每台服务器会被加入到相应的资源池中
   - 对于每个具体MySQL实例，管理员会根据应用部署在哪些机房、需要哪些计算资源等因素，为该MySQL实例具体指定主库和从库所在的资源池，然后，系统的实例管理服务会本着负载均衡的原则，从资源池中选择负载较轻的服务器来创建MySQL实例
5. **资源调度**
   - UMP系统中有三种规格的用户，分别是数据量和流量比较小的用户、中等规模用户以及需要分库分表的用户
   - 多个小规模用户可以共享同一个MySQL实例
   - 对于中等规模的用户，每个用户独占一个MySQL实例
   - 对于分库分表的用户，会占有多个独立的MySQL实例
6. **资源隔离**
   - ![image-20220411121035701](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220411121035.png)
7. **数据安全**
  
   - UMP系统设计了多种机制来保证数据安全：
   
     **•SSL数据库连接：**SSL(Secure Sockets Layer)是为网络通信提供安全及数据完整性的一种安全协议，它在传输层对网络连接进行加密。Proxy服务器实现了完整的MySQL客户端/服务器协议，可以与客户端之间建立SSL数据库连接
   
     **•数据访问IP白名单：**可以把允许访问云数据库的IP地址放入“白名单”，只有白名单内的IP地址才能访问，其他IP地址的访问都会被拒绝，从而进一步保证账户安全
   
     **•记录用户操作日志**：用户的所有操作记录都会被记录到日志分析服务器，通过检查用户操作记录，可以发现隐藏的安全漏洞
   
     **•SQL拦截：**Proxy服务器可以根据要求拦截多种类型的SQL语句，比如全表扫描语句“select *” 

## 6.4 Amazon AWS和云数据库

# 7.MapReduce

## 7.1	概述

### 7.1.1	分布式并行编程

- “摩尔定律”， CPU性能大约每隔18个月翻一番
- 从2005年开始摩尔定律逐渐失效 ，需要处理的数据量快速增加，人们开始借助于**分布式并行编程来提高程序性能** 
- 分布式程序运行在大规模**计算机集群**上，可以并行执行**大规模数据处理任务**，从而获得海量的计算能力
- 谷歌公司最先提出了分布式并行编程模型MapReduce，Hadoop MapReduce是它的开源实现，后者比前者使用门槛低很多 

问题：在MapReduce出现之前，已经有像MPI这样非常成熟的并行计算框架了，那么为什么Google还需要MapReduce？MapReduce相较于传统的并行计算框架有什么优势？

|                  | **传统并行计算框架**                      | **MapReduce**              |
| ---------------- | ----------------------------------------- | -------------------------- |
| 集群架构/容错性  | 共享式(共享内存/共享存储)，容错性差       | 非共享式，容错性好         |
| 硬件/价格/扩展性 | 刀片服务器、高速网、SAN，价格贵，扩展性差 | 普通PC机，便宜，扩展性好   |
| 编程/学习难度    | what-how，难                              | what，简单                 |
| 适用场景         | 实时、细粒度计算、计算密集型              | 批处理、非实时、数据密集型 |

### 7.1.2 MapReduce模型简介

- MapReduce将复杂的、运行于大规模集群上的并行计算过程高度地抽象到了两个函数：
  - **Map**
  - **Reduce**
- 编程容易，不需要掌握分布式并行编程细节，也可以很容易把自己的程序运行在分布式系统上，完成海量数据的计算
- MapReduce采用“**分而治之**”策略，一个存储在分布式文件系统中的大规模数据集，会被切分成许多独立的分片（split），这些分片可以被多个Map任务并行处理
- ==MapReduce设计的一个理念就是“**计算向数据靠拢**”，而不是“数据向计算靠拢”，因为，移动数据需要大量的网络传输开销==
- MapReduce框架采用了Master/Slave架构，包括一个Master和若干个Slave。Master上运行JobTracker，Slave上运行TaskTracker 
- Hadoop框架是用Java实现的，但是，MapReduce应用程序则不一定要用Java来写 

### 7.1.3 Map和Reduce函数

![image-20220418110709193](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418110709.png)

## 7.2 MapReduce的体系结构

MapReduce体系结构主要由四个部分组成，分别是：

- **Client**
- **JobTracker**
- **TaskTracker**
- **Task**

![image-20220418111247764](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418111248.png)



MapReduce主要有以下4个部分组成：

**1）Client**

- 用户编写的MapReduce程序通过<u>Client提交到JobTracker端</u>
- 用户可通过Client提供的一些接口<u>查看作业运行状态</u>

**2）JobTracker**

- JobTracker负责资源<u>监控和作业调度</u>
- JobTracker <u>监控所有TaskTracker与Job的健康状况</u>，一旦发现失败，就将相应的任务转移到其他节点
- JobTracker 会<u>跟踪任务的执行进度、资源使用量等信息</u>，并将这些信息告诉任务调度器（TaskScheduler），而调度器会在资源出现空闲时，选择合适的任务去使用这些资源

**3）TaskTracker**

- TaskTracker 会<u>周期性</u>地通过“心跳”将<u>本节点上资源的使用情况和任务的运行进度汇报给JobTracker</u>，同时<u>接收</u>JobTracker 发送过来的<u>命令</u>并执行相应的操作（如启动新任务、杀死任务等）
- TaskTracker <u>使用“slot”等量划分本节点上的资源量</u>（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop调度器的作用就是将各个TaskTracker上的空闲slot分配给Task使用。<u>slot 分为Map slot 和Reduce slot 两种，分别供MapTask 和Reduce Task 使用</u>

**4）Task**

- Task 分为
  - **Map Task**
  - **Reduce Task** 
- 均由TaskTracker 启动

## 7.3 MapReduce工作流程

### 7.3.1 工作流程概述

![image-20220418113127548](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418113127.png)

- 不同的Map任务之间不会进行通信
- 不同的Reduce任务之间也不会发生任何信息交换
- 用户不能显式地从一台机器向另一台机器发送消息
- 所有的数据交换都是通过MapReduce框架自身去实现的

### 7.3.2 MapReduce各个执行阶段

![image-20220418113641356](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418113641.png)

#### 关于Split（分片）

![image-20220418114833406](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418114833.png)

HDFS 以固定大小的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。**split 是一个逻辑概念**，它只包含一些元数据信息，比如数据起始位置、数据长度、数据所在节点等。它的**划分方法完全由用户自己决定。**

##### Map任务的数量

Hadoop为每个split创建一个Map任务，split 的多少决定了Map任务的数目。大多数情况下，**理想的分片大小是一个block块**

![image-20220418115148471](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418115148.png)

##### Reduce任务的数量

- 最优的**Reduce任务个数取决于集群中可用的reduce任务槽(slot)的数目**
- 通常设置比reduce任务槽数目稍微小一些的Reduce任务个数（这样可以预留一些系统资源处理可能发生的错误）

### 7.3.3 Shuffle过程详解

#### 1. Shuffle过程简介

![image-20220418115652664](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418115652.png)

#### **2. Map端的Shuffle过程(考点)**

![image-20220418121037394](https://cdn.jsdelivr.net/gh/stingo1218/pic/img/20220418121037.png)

> **合并（Combine）和归并（Merge）的区别：**
>
> 两个键值对<“a”,1>和<“a”,1>，如果合并，会得到<“a”,2>，如果归并，会得到<“a”,<1,1>>
